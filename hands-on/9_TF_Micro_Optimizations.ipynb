{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1eSkHZaLzMId"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92-4Hjy7kA8"
      },
      "source": [
        "# Gesture Classification With Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDA8AK7QOq-"
      },
      "source": [
        "## Setup Python Environment\n",
        "\n",
        "The next cell sets up the dependencies in required for the notebook, run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2gs-PL4xDkZ"
      },
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd\n",
        "# !pip install pandas numpy matplotlib\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "# !pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lwkeshJk7dg"
      },
      "source": [
        "## Get Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXzdey6thBCE"
      },
      "source": [
        "!wget https://github.com/robmarkcole/arduino-tensorflow-example/archive/master.tar.gz\n",
        "!tar xzf master.tar.gz\n",
        "!mv arduino-tensorflow-example-master/content data\n",
        "!rm -rf arduino-tensorflow-example-master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh9yve14gUyD"
      },
      "source": [
        "## Plot Data\n",
        "\n",
        "We'll graph the input files on two separate graphs, acceleration and gyroscope, as each data set has different units and scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I65ukChEgyNp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "filename = \"punch.csv\"\n",
        "# filename = \"flex.csv\"\n",
        "\n",
        "df = pd.read_csv(\"data/\" + filename)\n",
        "\n",
        "index = range(1, len(df['aX']) + 1)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (12,4)\n",
        "\n",
        "plt.plot(index, df['aX'], 'g.', label='x', linestyle='solid', marker=',')\n",
        "plt.plot(index, df['aY'], 'b.', label='y', linestyle='solid', marker=',')\n",
        "plt.plot(index, df['aZ'], 'r.', label='z', linestyle='solid', marker=',')\n",
        "plt.title(\"Acceleration\")\n",
        "plt.xlabel(\"Sample #\")\n",
        "plt.ylabel(\"Acceleration (G)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(index, df['gX'], 'g.', label='x', linestyle='solid', marker=',')\n",
        "plt.plot(index, df['gY'], 'b.', label='y', linestyle='solid', marker=',')\n",
        "plt.plot(index, df['gZ'], 'r.', label='z', linestyle='solid', marker=',')\n",
        "plt.title(\"Gyroscope\")\n",
        "plt.xlabel(\"Sample #\")\n",
        "plt.ylabel(\"Gyroscope (deg/sec)\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxk414PU3oy3"
      },
      "source": [
        "## Parse and prepare the data\n",
        "\n",
        "The next cell parses the csv files and transforms them to a format that will be used to train the fully connected neural network.\n",
        "\n",
        "Update the `GESTURES` list with the gesture data you've collected in `.csv` format.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGChd1FAk5_j"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
        "# the same random numbers each time the notebook is run\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# the list of gestures that data is available for\n",
        "GESTURES = [\n",
        "    \"punch\",\n",
        "    \"flex\",\n",
        "]\n",
        "\n",
        "SAMPLES_PER_GESTURE = 119\n",
        "\n",
        "NUM_GESTURES = len(GESTURES)\n",
        "\n",
        "# create a one-hot encoded matrix that is used in the output\n",
        "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "for gesture_index in range(NUM_GESTURES):\n",
        "  gesture = GESTURES[gesture_index]\n",
        "  print(f\"Processing index {gesture_index} for gesture '{gesture}'.\")\n",
        "\n",
        "  output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
        "\n",
        "  df = pd.read_csv(\"data/\" + gesture + \".csv\")\n",
        "\n",
        "  # calculate the number of gesture recordings in the file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
        "\n",
        "  print(f\"\\tThere are {num_recordings} recordings of the {gesture} gesture.\")\n",
        "\n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    for j in range(SAMPLES_PER_GESTURE):\n",
        "      index = i * SAMPLES_PER_GESTURE + j\n",
        "      # normalize the input data, between 0 to 1:\n",
        "      # - acceleration is between: -4 to +4\n",
        "      # - gyroscope is between: -2000 to +2000\n",
        "      tensor += [\n",
        "          (df['aX'][index] + 4) / 8,\n",
        "          (df['aY'][index] + 4) / 8,\n",
        "          (df['aZ'][index] + 4) / 8,\n",
        "          (df['gX'][index] + 2000) / 4000,\n",
        "          (df['gY'][index] + 2000) / 4000,\n",
        "          (df['gZ'][index] + 2000) / 4000\n",
        "      ]\n",
        "\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "# convert the list to numpy array\n",
        "inputs = np.array(inputs, dtype='float32')\n",
        "outputs = np.array(outputs, dtype='float32')\n",
        "\n",
        "print(\"Data set parsing and preparation complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5_61831d5AM"
      },
      "source": [
        "## Randomize and split the input and output pairs for training\n",
        "\n",
        "Randomly split input and output pairs into sets of data: 60% for training, 20% for validation, and 20% for testing.\n",
        "\n",
        "  - the training set is used to train the model\n",
        "  - the validation set is used to measure how well the model is performing during training\n",
        "  - the testing set is used to test the model after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfNEmUZMeIEx"
      },
      "source": [
        "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
        "# https://stackoverflow.com/a/37710486/2020087\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Data set randomization and splitting complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9g2n41p24nR"
      },
      "source": [
        "## Build & Train the Model\n",
        "\n",
        "Build and train a [TensorFlow](https://www.tensorflow.org) model using the high-level [Keras](https://www.tensorflow.org/guide/keras) API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGNFa-lX24Qo"
      },
      "source": [
        "# build the model and train it\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu')) # relu is used for performance\n",
        "model.add(tf.keras.layers.Dense(15, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax')) # softmax is used, because we only expect one gesture to occur per input\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=600, batch_size=1, validation_data=(inputs_validate, outputs_validate))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb2ROTzUylGU"
      },
      "source": [
        "print(model.summary())\n",
        "model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUDPvaJE1wRE"
      },
      "source": [
        "## Verify\n",
        "\n",
        "Graph the models performance vs validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvFNHXoQzmcM"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (10,4)\n",
        "\n",
        "# graph the loss, the model above is configure to use \"mean squared error\" as the loss function\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g-', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b-', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(plt.rcParams[\"figure.figsize\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRjvkFQy2RgS"
      },
      "source": [
        "[Mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) is another metric to judge the performance of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBjCf1-2zx9C"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (10,4)\n",
        "\n",
        "# graph of mean absolute error\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "plt.plot(epochs[:], mae[:], 'g-', label='Training MAE')\n",
        "plt.plot(epochs[:], val_mae[:], 'b-', label='Validation MAE')\n",
        "plt.title('Training and validation mean absolute error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aT6kxsIqHlX"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(inputs_test, outputs_test, verbose=2)\n",
        "print('Test MAE (attention, NOT accuracy):', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7DO6xxXVCym"
      },
      "source": [
        "# Convert the Trained Model to Tensor Flow Lite\n",
        "\n",
        "The next cell converts the model to TFlite format. The size in bytes of the model is also printed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn1-Rn9Cp_8"
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLZIQpcZWnwQ"
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "def representative_dataset():\n",
        "  for i in range(18):\n",
        "    yield([inputs_train[i].reshape(-1)])\n",
        "\n",
        "# Set the optimization flag.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# Enforce integer only quantization\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "# Provide a representative dataset to ensure we quantize correctly.\n",
        "# This enables the converter to estimate a dynamic range for all the variable data.\n",
        "converter.representative_dataset = representative_dataset\n",
        "tflite_model_opt = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model_opt.tflite\", \"wb\").write(tflite_model_opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E_bvxEGfq-P"
      },
      "source": [
        "### 2. Compare Model Performance\n",
        "\n",
        "To prove these models are accurate even after conversion and quantization, we'll compare their predictions and loss on our test dataset.\n",
        "\n",
        "**Helper functions**\n",
        "\n",
        "We define the `predict` (for predictions) and `evaluate` (for loss) functions for TFLite models. *Note: These are already included in a TF model, but not in  a TFLite model.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDiS9Mm8fphn"
      },
      "source": [
        "def predict_tflite(tflite_model, x_test):\n",
        "  # Prepare the test data\n",
        "  x_test_ = x_test.copy()\n",
        "  # x_test_ = x_test_.reshape((x_test.size, 1))\n",
        "  # x_test_ = x_test_.astype(np.float32)\n",
        "\n",
        "  # Initialize the TFLite interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "  # If required, quantize the input layer (from float to integer)\n",
        "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "  if (input_scale, input_zero_point) != (0.0, 0):\n",
        "    x_test_ = x_test_ / input_scale + input_zero_point\n",
        "    x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
        "\n",
        "  # Invoke the interpreter\n",
        "  # 2 below stands for two classes\n",
        "  y_pred = np.empty((x_test_.shape[0],2), dtype=output_details[\"dtype\"])\n",
        "  for i in range(len(x_test_)):\n",
        "    # print(x_test_.shape)\n",
        "    interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
        "    interpreter.invoke()\n",
        "    # print(interpreter.get_tensor(output_details[\"index\"]))\n",
        "    y_pred[i] = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "  # If required, dequantized the output layer (from integer to float)\n",
        "  output_scale, output_zero_point = output_details[\"quantization\"]\n",
        "  if (output_scale, output_zero_point) != (0.0, 0):\n",
        "    y_pred = y_pred.astype(np.float32)\n",
        "    y_pred = (y_pred - output_zero_point) * output_scale\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "def evaluate_tflite(tflite_model, x_test, y_true):\n",
        "  global model\n",
        "  y_pred = predict_tflite(tflite_model, x_test)\n",
        "  loss_function = tf.keras.losses.get(model.loss)\n",
        "  # print(y_true)\n",
        "  # print(y_pred)\n",
        "  # print('\\n')\n",
        "  loss = loss_function(np.argmax(y_true, axis=1), np.argmax(y_pred, axis=1)).numpy()\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsNwVLRYhIlY"
      },
      "source": [
        "# Calculate loss\n",
        "loss_model, _ = model.evaluate(inputs_test, outputs_test, verbose=0)\n",
        "loss_tflite_model = evaluate_tflite(tflite_model, inputs_test, outputs_test)\n",
        "loss_tflite_model_opt = evaluate_tflite(tflite_model_opt, inputs_test, outputs_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLw7GzWJnm94"
      },
      "source": [
        "# Compare loss\n",
        "df = pd.DataFrame.from_records(\n",
        "    [[\"TensorFlow\", loss_model],\n",
        "     [\"TensorFlow Lite\", loss_tflite_model],\n",
        "     [\"TensorFlow Lite Opt\", loss_tflite_model_opt]],\n",
        "     columns = [\"Model\", \"Loss/MSE\"], index=\"Model\")\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykccQn7SXrUX"
      },
      "source": [
        "# Encode the Model in an Arduino Header File\n",
        "\n",
        "The next cell creates a constant byte array that contains the TFlite model. Import it as a tab with the sketch below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J33uwpNtAku"
      },
      "source": [
        "!echo \"const unsigned char model[] = {\"   > model.h\n",
        "!cat gesture_model_opt.tflite | xxd -i    >> model.h\n",
        "!echo \"};\"                                >> model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-QtpclDFNnJ"
      },
      "source": [
        "Now it's time to switch back to the tutorial instructions and run our new model on the Arduino Nano 33 BLE Sense to classify the accelerometer and gyroscope data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute FLOPs"
      ],
      "metadata": {
        "id": "ylxlymglDUN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_flops(model_h5_path):\n",
        "    session = tf.compat.v1.Session()\n",
        "    graph = tf.compat.v1.get_default_graph()\n",
        "\n",
        "    with graph.as_default():\n",
        "        with session.as_default():\n",
        "            model = tf.keras.models.load_model(model_h5_path)\n",
        "\n",
        "            run_meta = tf.compat.v1.RunMetadata()\n",
        "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
        "\n",
        "            # We use the Keras session graph in the call to the profiler.\n",
        "            flops = tf.compat.v1.profiler.profile(graph=graph,\n",
        "                                                  run_meta=run_meta, cmd='op', options=opts)\n",
        "\n",
        "            return flops.total_float_ops\n",
        "\n",
        "tf.compat.v1.reset_default_graph()\n",
        "flops = get_flops('model.h5')\n",
        "print(\"Number of FLOPs: \", flops)"
      ],
      "metadata": {
        "id": "V88Eii7uDRxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eSkHZaLzMId"
      },
      "source": [
        "# Links\n",
        "\n",
        "*   https://github.com/arduino/ArduinoTensorFlowLiteTutorials/\n"
      ]
    }
  ]
}